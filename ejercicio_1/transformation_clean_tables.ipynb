{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_archivo = '/home/tonatiuh/Documents/Desarrollo/ZophiaLearning/ejercicios/'\n",
    "dir_complemento = 'prestamos/stage/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivos = [\n",
    "    'prestamos_bancos.parquet',\n",
    "    'prestamos_destinatarios.parquet',\n",
    "    'prestamos_pagos.parquet',\n",
    "    'prestamos_plaza.parquet',\n",
    "    'prestamos_solicitudes.parquet',\n",
    "    'prestamos_solicitudes_procesadas.parquet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_almacenamiento_parquet(dir_archivo, nombre_archivo, df):\n",
    "    nombre_destino = f'prestamos/curated/{nombre_archivo}'\n",
    "    df.write.mode('overwrite').parquet(dir_archivo+nombre_destino)\n",
    "    print(nombre_destino)\n",
    "\n",
    "    \n",
    "def df_almacenamiento_csv(nombre_archivo, df):\n",
    "    df_filtrado = df.limit(10)\n",
    "    df_pandas = df_filtrado.toPandas()\n",
    "    nombre_output = nombre_archivo.replace('.parquet', '')\n",
    "    nombre_csv = f'output/{nombre_output}.csv'\n",
    "    df_pandas.to_csv(nombre_csv, index=False)\n",
    "    print(nombre_csv)\n",
    "\n",
    "\n",
    "def df_almacenamiento(dir_archivo, nombre_archivo, df):\n",
    "    df_almacenamiento_parquet(dir_archivo, nombre_archivo, df)\n",
    "    df_almacenamiento_csv(nombre_archivo, df)\n",
    "\n",
    "    \n",
    "letras_acento = 'áéíóúÁÉÍÓÚ'\n",
    "letras_sin_acento = 'aeiouAEIOU'\n",
    "tabla_acentos = str.maketrans(letras_acento, letras_sin_acento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla prestamos_bancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[0]\n",
    "df_bancos = spark.read.format('parquet')\\\n",
    "                .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "\n",
    "for col_nombre in ['digitos', 'BANCO']:\n",
    "    df_bancos = df_bancos.withColumn(col_nombre, F.translate(col_nombre, \"'\", \"\"))\n",
    "    df_bancos = df_bancos.withColumnRenamed(col_nombre, col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DIGITOS: string (nullable = true)\n",
      " |-- BANCO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bancos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|DIGITOS|        BANCO|\n",
      "+-------+-------------+\n",
      "|    002|      BANAMEX|\n",
      "|    006|    BANCOMEXT|\n",
      "|    009|     BANOBRAS|\n",
      "|    012|BBVA BANCOMER|\n",
      "|    014|    SANTANDER|\n",
      "+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bancos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_bancos.parquet\n",
      "output/prestamos_bancos.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_bancos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla prestamos_destinatarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[1]\n",
    "df_destinatarios = spark.read.format('parquet')\\\n",
    "                        .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "\n",
    "\n",
    "for col_nombre in ['ID', 'banco', 'plaza']:\n",
    "    df_destinatarios = df_destinatarios.withColumn(col_nombre,\n",
    "                                                   F.col(col_nombre).cast(IntegerType()))\n",
    "    \n",
    "    df_destinatarios = df_destinatarios.withColumnRenamed(col_nombre,\n",
    "                                                          col_nombre.upper())\n",
    "\n",
    "    \n",
    "for col_nombre in ['cp', 'fecha_nacimiento', 'correo', 'clabe']:\n",
    "    df_destinatarios = df_destinatarios.withColumnRenamed(col_nombre,\n",
    "                                                          col_nombre.upper())\n",
    "\n",
    "\n",
    "for col_nombre in ['nombre', 'direccion', 'empleo', 'empleador']:\n",
    "    df_destinatarios = df_destinatarios.withColumn(col_nombre, \n",
    "                                                   F.translate(col_nombre,\n",
    "                                                               letras_acento,\n",
    "                                                               letras_sin_acento))\n",
    "    \n",
    "    df_destinatarios = df_destinatarios.withColumn(col_nombre,\n",
    "                                                   F.translate(col_nombre, '\\n', ''))\n",
    "    \n",
    "    df_destinatarios = df_destinatarios.withColumnRenamed(col_nombre,\n",
    "                                                          col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- NOMBRE: string (nullable = true)\n",
      " |-- DIRECCION: string (nullable = true)\n",
      " |-- CP: string (nullable = true)\n",
      " |-- FECHA_NACIMIENTO: string (nullable = true)\n",
      " |-- EMPLEO: string (nullable = true)\n",
      " |-- EMPLEADOR: string (nullable = true)\n",
      " |-- CORREO: string (nullable = true)\n",
      " |-- BANCO: integer (nullable = true)\n",
      " |-- PLAZA: integer (nullable = true)\n",
      " |-- CLABE: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_destinatarios.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------\n",
      " ID               | 0                                                     \n",
      " NOMBRE           | Sr(a). Luz Leon                                       \n",
      " DIRECCION        | Diagonal Argelia 602 655San Caridad de la Montaña, BC \n",
      " CP               | 76193                                                 \n",
      " FECHA_NACIMIENTO | 1960-12-12                                            \n",
      " EMPLEO           | Biomedical engineer                                   \n",
      " EMPLEADOR        | Najera y Estrada e Hijos                              \n",
      " CORREO           | pablo10@gmail.com                                     \n",
      " BANCO            | 147                                                   \n",
      " PLAZA            | 396                                                   \n",
      " CLABE            | 25944813986                                           \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_destinatarios.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_destinatarios.parquet\n",
      "output/prestamos_destinatarios.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_destinatarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla pagos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[2]\n",
    "df_pagos = spark.read.format('parquet')\\\n",
    "                .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "df_pagos = df_pagos.select('fecha', 'cantidad', 'prestamo')\n",
    "\n",
    "\n",
    "col_nombre = 'fecha'\n",
    "df_pagos = df_pagos.withColumnRenamed(col_nombre,\n",
    "                                      col_nombre.upper())\n",
    "\n",
    "\n",
    "col_nombre = 'cantidad'\n",
    "df_pagos = df_pagos.withColumn(col_nombre,\n",
    "                               F.col(col_nombre).cast(DoubleType()))\n",
    "\n",
    "df_pagos = df_pagos.withColumnRenamed(col_nombre,\n",
    "                                      col_nombre.upper())\n",
    "\n",
    "\n",
    "col_nombre = 'prestamo'\n",
    "df_pagos = df_pagos.withColumn(col_nombre,\n",
    "                               F.translate(col_nombre, '[]', ''))\n",
    "\n",
    "df_pagos = df_pagos.withColumnRenamed(col_nombre,\n",
    "                                      col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FECHA: string (nullable = true)\n",
      " |-- CANTIDAD: double (nullable = true)\n",
      " |-- PRESTAMO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pagos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+\n",
      "|     FECHA|CANTIDAD|PRESTAMO|\n",
      "+----------+--------+--------+\n",
      "|2017-02-14| 13100.0|     381|\n",
      "|2017-02-15|  2500.0|     273|\n",
      "|2017-02-27|  5000.0|     381|\n",
      "|2017-03-01|  2700.0|    1662|\n",
      "|2017-03-13|  6000.0|    1662|\n",
      "+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pagos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_pagos.parquet\n",
      "output/prestamos_pagos.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_pagos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla plaza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[3]\n",
    "df_plaza = spark.read.format('parquet')\\\n",
    "                .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "\n",
    "col_nombre = 'digitos'\n",
    "df_plaza = df_plaza.withColumn(col_nombre,\n",
    "                               F.translate(col_nombre, \"'\", \"\"))\n",
    "\n",
    "df_plaza = df_plaza.withColumnRenamed(col_nombre,\n",
    "                                      col_nombre.upper())\n",
    "\n",
    "col_nombre = 'PLAZA'\n",
    "df_plaza = df_plaza.withColumn(col_nombre,\n",
    "                               F.translate(col_nombre, \"'\", \"\"))\n",
    "\n",
    "df_plaza = df_plaza.withColumn(col_nombre, \n",
    "                               F.translate(col_nombre,\n",
    "                                           letras_acento,\n",
    "                                           letras_sin_acento))\n",
    "\n",
    "df_plaza = df_plaza.withColumnRenamed(col_nombre,\n",
    "                                      col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DIGITOS: string (nullable = true)\n",
      " |-- PLAZA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_plaza.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|DIGITOS|         PLAZA|\n",
      "+-------+--------------+\n",
      "|    010|Aguascalientes|\n",
      "|    314|       Zimapan|\n",
      "|    640|      Zimatlan|\n",
      "|    012|      Calvillo|\n",
      "|    320|      El Salto|\n",
      "+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_plaza.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_plaza.parquet\n",
      "output/prestamos_plaza.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_plaza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla solicitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[4]\n",
    "df_solicitudes = spark.read.format('parquet')\\\n",
    "                        .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "\n",
    "\n",
    "for col_nombre in ['ID', 'fecha', 'fecha_in', 'fecha_lim',\n",
    "                   'monto', 'taza', 'fecha_pago']:\n",
    "    df_solicitudes = df_solicitudes.withColumnRenamed(col_nombre,\n",
    "                                                      col_nombre.upper())\n",
    "\n",
    "    \n",
    "col_nombre = 'descripcion'\n",
    "df_solicitudes = df_solicitudes.withColumn(col_nombre,\n",
    "                                           F.col(col_nombre).cast(FloatType()))\n",
    "\n",
    "df_solicitudes = df_solicitudes.withColumnRenamed(col_nombre,\n",
    "                                                  col_nombre.upper())\n",
    "\n",
    "\n",
    "for col_nombre in ['producto', 'solicitante']:\n",
    "    df_solicitudes = df_solicitudes.withColumn(col_nombre, \n",
    "                                               F.translate(col_nombre,\n",
    "                                                           letras_acento,\n",
    "                                                           letras_sin_acento))\n",
    "    \n",
    "    df_solicitudes = df_solicitudes.withColumnRenamed(col_nombre,\n",
    "                                                      col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- FECHA: string (nullable = true)\n",
      " |-- FECHA_IN: string (nullable = true)\n",
      " |-- FECHA_LIM: string (nullable = true)\n",
      " |-- MONTO: long (nullable = true)\n",
      " |-- PRODUCTO: string (nullable = true)\n",
      " |-- TAZA: double (nullable = true)\n",
      " |-- DESCRIPCION: float (nullable = true)\n",
      " |-- FECHA_PAGO: string (nullable = true)\n",
      " |-- SOLICITANTE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_solicitudes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " ID          | 0                   \n",
      " FECHA       | 2017-06-14          \n",
      " FECHA_IN    | 2017-06-14          \n",
      " FECHA_LIM   | 2018-07-09          \n",
      " MONTO       | 255000              \n",
      " PRODUCTO    | monina              \n",
      " TAZA        | 4.5                 \n",
      " DESCRIPCION | null                \n",
      " FECHA_PAGO  | 2018-07-09          \n",
      " SOLICITANTE | Oliver Correa Tello \n",
      "-RECORD 1--------------------------\n",
      " ID          | 1                   \n",
      " FECHA       | 2017-03-21          \n",
      " FECHA_IN    | 2017-03-21          \n",
      " FECHA_LIM   | 2017-08-18          \n",
      " MONTO       | 84000               \n",
      " PRODUCTO    | basico              \n",
      " TAZA        | 8.1                 \n",
      " DESCRIPCION | null                \n",
      " FECHA_PAGO  | 2017-08-18          \n",
      " SOLICITANTE | Augusto Olmos       \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_solicitudes.show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_solicitudes.parquet\n",
      "output/prestamos_solicitudes.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_solicitudes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla solicitudes_procesadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = nombre_archivos[5]\n",
    "df_solicitudes_p = spark.read.format('parquet')\\\n",
    "                        .load(dir_archivo+dir_complemento+nombre_archivo)\n",
    "\n",
    "\n",
    "for col_nombre in ['fecha_aprobado', 'fecha_solicitud', 'fecha_limite',\n",
    "                   'monto_aprobado', 'solicitud_id', 'respuesta']:\n",
    "    df_solicitudes_p = df_solicitudes_p.withColumnRenamed(col_nombre,\n",
    "                                                          col_nombre.upper())\n",
    "\n",
    "\n",
    "col_nombre = 'monto_solicitado'\n",
    "df_solicitudes_p = df_solicitudes_p.withColumn(col_nombre,\n",
    "                                               F.col(col_nombre).cast(DoubleType()))\n",
    "\n",
    "df_solicitudes_p = df_solicitudes_p.withColumnRenamed(col_nombre,\n",
    "                                                      col_nombre.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FECHA_APROBADO: string (nullable = true)\n",
      " |-- FECHA_SOLICITUD: string (nullable = true)\n",
      " |-- FECHA_LIMITE: string (nullable = true)\n",
      " |-- MONTO_SOLICITADO: double (nullable = true)\n",
      " |-- MONTO_APROBADO: double (nullable = true)\n",
      " |-- SOLICITUD_ID: long (nullable = true)\n",
      " |-- RESPUESTA: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_solicitudes_p.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------\n",
      " FECHA_APROBADO   | 2017-07-18 \n",
      " FECHA_SOLICITUD  | 2017-07-02 \n",
      " FECHA_LIMITE     | 2018-07-09 \n",
      " MONTO_SOLICITADO | 255000.0   \n",
      " MONTO_APROBADO   | 0.0        \n",
      " SOLICITUD_ID     | 0          \n",
      " RESPUESTA        | false      \n",
      "-RECORD 1----------------------\n",
      " FECHA_APROBADO   | 2017-04-29 \n",
      " FECHA_SOLICITUD  | 2017-04-10 \n",
      " FECHA_LIMITE     | 2017-08-18 \n",
      " MONTO_SOLICITADO | 84000.0    \n",
      " MONTO_APROBADO   | 80000.0    \n",
      " SOLICITUD_ID     | 1          \n",
      " RESPUESTA        | true       \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_solicitudes_p.show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestamos/curated/prestamos_solicitudes_procesadas.parquet\n",
      "output/prestamos_solicitudes_procesadas.csv\n"
     ]
    }
   ],
   "source": [
    "df_almacenamiento(dir_archivo, nombre_archivo, df_solicitudes_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
